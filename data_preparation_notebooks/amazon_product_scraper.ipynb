{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b571e1",
   "metadata": {},
   "source": [
    "### Downloading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7627b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "# Open a new session in chrome browser\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# Path where the dataset is stored\n",
    "path = \"\"\n",
    "\n",
    "# Reading the columns asin and imgUrl\n",
    "df = pd.read_csv(path, usecols=[\"asin\", \"imgUrl\"])\n",
    "\n",
    "# Code for downloading the images\n",
    "failed = []\n",
    "start = int(input())\n",
    "end = int(input())\n",
    "for i in range(start, end):\n",
    "    # Declaring the name of the file which is saved using its id.jpg\n",
    "    # id is asin column\n",
    "    file_name = df[\"asin\"][i] + \".jpg\"\n",
    "    # Printing the image name that is to be downloaded\n",
    "    print(f\"{file_name}\")\n",
    "    # Fetching the image URL\n",
    "    img = df[\"imgUrl\"][I]\n",
    "    # Checking if there is an image in the URL\n",
    "    # if not skip that image\n",
    "    if img == \"No Image Found\":\n",
    "        continue\n",
    "    # getting the images using requests library\n",
    "    r = requests.get(img, stream=True)\n",
    "    # checking if the fetching the image was successful\n",
    "    # 200 is the success code and any other is failure\n",
    "    if r.status_code == 200:\n",
    "        # saving the image\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)\n",
    "    # if failed to get the image, add the product id (asin) in the failed list\n",
    "    else:\n",
    "        failed.append(df[\"asin\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cfc42",
   "metadata": {},
   "source": [
    "### Getting the product description from the Product Url given in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ab136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "# Open a new session in chrome browser\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# Path where the dataset is stored\n",
    "path = \"\"\n",
    "\n",
    "# Reading the columns asin and productUrl\n",
    "df = pd.read_csv(path, usecols=[\"asin\", \"productURL\"])\n",
    "\n",
    "# Code for fetching the product description\n",
    "product_desc = {}\n",
    "start = int(input())\n",
    "end = int(input())\n",
    "for i in tqdm(range(start, end)):\n",
    "    # fetching the product url from the dataset\n",
    "    browser.get(str(df[\"productURL\"][i]))\n",
    "    # fetching the xpath for the product descrtiption\n",
    "    found = browser.find_elements(By.XPATH, \"//*[@id='productDescription']/p/span\")\n",
    "    # checking if there is a section on product description\n",
    "    if len(found) > 0:\n",
    "        # getting the product description\n",
    "        p = browser.find_element(By.XPATH, \"//*[@id='productDescription']/p/span\")\n",
    "        # converting the format to text and adding in the dictionary\n",
    "        product_desc[df[\"asin\"][i]] = str(p.text)\n",
    "    # if the product description is not found, add in the dictionary no description found\n",
    "    else:\n",
    "        product_desc[df[\"asin\"][i]] = \"No description found\"\n",
    "\n",
    "# saving the results in the csv file named product_desc.csv\n",
    "data = {\"asin\": product_desc.keys(), \"productDescription\": product_desc.values()}\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.to_csv(\"prod_desc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093d136",
   "metadata": {},
   "source": [
    "### Getting the product details from the Product Url given in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "# Open a new session in chrome browser\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# Path where the dataset is stored\n",
    "path = \"\"\n",
    "\n",
    "# Reading the columns asin and productUrl\n",
    "df = pd.read_csv(path, usecols=[\"asin\", \"productURL\"])\n",
    "\n",
    "# Code for fetching the product details\n",
    "start = int(input())\n",
    "end = int(input())\n",
    "for i in tqdm(range(start, end)):\n",
    "    # fetching the product url from the dataset\n",
    "    browser.get(str(df[\"productURL\"][i]))\n",
    "    # fetching the xpath for the product details\n",
    "    found = browser.find_element(By.XPATH, '//*[@id=\"prodDetails\"]')\n",
    "    # checking if there is a section on product details\n",
    "    if len(found) > 0:\n",
    "        # converting the format to text and adding in the dictionary\n",
    "        product_info[df[\"asin\"][i]] = str(found.text)\n",
    "    # if the product details section is not present, add in the dictionary no product info found\n",
    "    else:\n",
    "        product_info[df[\"asin\"][i]] = str(\"No product Info found\")\n",
    "\n",
    "# saving the results in the csv file named product_info.csv\n",
    "data = {\"asin\": product_desc.keys(), \"productDescription\": product_info.values()}\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.to_csv(\"prod_info.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
